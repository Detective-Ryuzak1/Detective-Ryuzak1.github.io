<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blog de Tecnolog√≠a</title>
    <link rel="icon" href="../media/imagen41.png" type="image/png">
    <script src="https://kit.fontawesome.com/9474e300a6.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="../css/estilos-articulo.css">
</head>
<body>

    <header>
        <div class="container__header">
            <div class="logo">
                <img src="../media/logo-1.png" alt="">
            </div>

            <div class="menu">
                <nav>
                    <ul>
                        <li><a href="../index.html">Inicio</a></li>
                        <li><a href="../electronica.html">Electr√≥nica</a></li>
                        <li><a href="../network.html">Networking</a></li>
                        <li><a href="../ia.html">Inteligencia Artificial</a></li>
                        <li><a href="../hacking.html">Ciberseguridad</a></li>
                        <li><a href="../devops.html">DevOps</a></li>
                    </ul>
                </nav>
            </div>
            <i class="fa-solid fa-bars" style="color: #ffffff;" id="icon_menu"></i>
            <div class="header__botonMenu">
                <input type="button" class="btn__header-botonMenu" value="Aportar" onclick="window.open('https://buymeacoffee.com/ryuzak1', '_blank');">
            </div>
        </div>
    </header>
    <main>
        <div class="cover">
            <div class="text__articulo-cover">
                <br>
                <br>
                <h1>Apache Flink</h1>
                <p>Apache Flink es un sistema de procesamiento de datos distribuido y una plataforma de an√°lisis de flujos en tiempo real. Est√° dise√±ado para ejecutar aplicaciones de procesamiento de eventos con baja latencia, alto rendimiento y una fuerte capacidad de recuperaci√≥n ante fallos. Nacido en el ecosistema de proyectos de c√≥digo abierto de la Apache Software Foundation, Flink ha ganado protagonismo como una alternativa avanzada a otros motores de procesamiento, particularmente por su enfoque nativo al streaming de datos.</p>
                <p>A diferencia de motores como Hadoop o Spark que nacieron bajo paradigmas batch y luego evolucionaron al streaming, Flink fue construido desde cero para el procesamiento continuo, lo cual lo convierte en una herramienta clave para aplicaciones donde los datos nunca se detienen, como an√°lisis de logs en tiempo real, detecci√≥n de fraudes financieros, sistemas de monitoreo o an√°lisis de redes sociales.</p>
                <ul style="list-style-type: none;">
                    <li>‚àò Procesamiento de eventos en tiempo real (true streaming).</li>
                    <li>‚àò Baja latencia y alto rendimiento.</li>
                    <li>‚àò Tolerancia a fallos avanzada.</li>
                    <li>‚àò Soporte para estado (stateful processing).</li>
                    <li>‚àò Integraci√≥n con m√∫ltiples fuentes de datos (Kafka, HDFS, JDBC, etc.).</li>
                </ul>
                <div class="blog-image-grande">
                    <img src="media/flink1.jpeg" alt="">
                </div>
                <h2>Componentes principales</h2>
                <p>La arquitectura de Flink est√° compuesta por varios componentes que trabajan en conjunto para orquestar el procesamiento de datos en un cl√∫ster distribuido. Estos son los pilares que permiten a Flink manejar trabajos complejos con eficiencia:</p>
                <ul style="list-style-type: none;">
                    <li>‚û∞ <marcador class="resaltado2">JobManager: </marcador>Es el componente maestro. Su responsabilidad es coordinar la ejecuci√≥n de los trabajos, distribuir las tareas a los nodos trabajadores (TaskManagers), y manejar el estado del trabajo, los checkpoints y las recuperaciones en caso de fallos. Se puede configurar en modo de alta disponibilidad (HA).</li>
                    <li>‚û∞ <marcador class="resaltado2">TaskManager: </marcador>Es el componente que ejecuta las tareas individuales. Cada TaskManager gestiona un n√∫mero configurable de slots, donde cada slot representa la capacidad para ejecutar una sub-tarea de manera paralela. Estos nodos tambi√©n se comunican entre s√≠ para intercambiar datos intermedios.</li>
                    <li>‚û∞ <marcador class="resaltado2">Dispatcher y ResourceManager: </marcador>En una arquitectura moderna de Flink (desde la integraci√≥n con Kubernetes o Yarn), el Dispatcher recibe las peticiones de los trabajos, mientras que el ResourceManager interact√∫a con el gestor de recursos del cl√∫ster para aprovisionar nodos seg√∫n necesidad.</li>
                    <li>‚û∞ <marcador class="resaltado2">State Backend: </marcador>Es el componente que define c√≥mo y d√≥nde se guarda el estado del trabajo. Puede usarse memoria, sistemas de archivos distribuidos como HDFS o bases de datos especializadas como RocksDB para manejar estados grandes.</li>
                    <li>‚û∞ <marcador class="resaltado2">Checkpointing System: </marcador>Este sistema realiza instant√°neas del estado del trabajo en intervalos definidos, permitiendo que, en caso de fallos, la ejecuci√≥n pueda continuar desde el √∫ltimo checkpoint sin p√©rdida de datos ni inconsistencia.</li>
                    <li>‚û∞ <marcador class="resaltado2">APIs de Flink: </marcador>Flink proporciona m√∫ltiples APIs como la DataStream API (para flujos no estructurados), la Table API (similar a SQL para flujos y lotes) y la SQL API, que facilita el acceso a analistas y usuarios no t√©cnicos.</li>
                </ul>
                <div class="blog-image-grande">
                    <img src="media/flink2.jpg" alt="">
                </div>
                <h2>¬øC√≥mo funciona Apache Flink?</h2>
                <p>El funcionamiento de Apache Flink gira alrededor de un modelo de procesamiento de eventos individuales, lo que lo convierte en un verdadero motor de streaming. Cuando un trabajo es lanzado, Flink construye un grafo dirigido ac√≠clico (DAG) de operaciones, conocido como Job Graph. Este grafo es transformado en un Execution Graph, donde cada nodo representa una operaci√≥n l√≥gica del pipeline.</p>
                <p>Una vez desplegado, Flink empieza a recibir eventos en tiempo real desde las fuentes configuradas (como Kafka, Kinesis, sockets, archivos, etc.). Cada evento es procesado tan pronto como llega, a diferencia del modelo por lotes o micro-lotes. Esta es una de sus mayores fortalezas, ya que permite tiempos de respuesta muy reducidos. El sistema puede mantener estado asociado a cada clave del flujo de datos (por ejemplo, el saldo de una cuenta bancaria, un contador, un mapa de sesiones activas, etc.), lo que permite construir aplicaciones que requieren memoria de eventos anteriores.</p>
                <p>El estado en Flink puede ser almacenado en memoria para operaciones r√°pidas, o en backends externos como RocksDB para operaciones de mayor volumen. Este estado es tolerante a fallos gracias al mecanismo de checkpointing distribuido. Cuando ocurre una interrupci√≥n o fallo, Flink reinicia las tareas desde el √∫ltimo checkpoint sin volver a procesar los eventos ya entregados, garantizando exactly-once semantics en la mayor√≠a de los casos.</p>
                <p>Una de las capacidades m√°s avanzadas de Flink es el procesamiento basado en event-time, lo que permite procesar los datos en funci√≥n del momento en que ocurrieron, y no en el orden de llegada. Esto es clave cuando trabajamos con sistemas distribuidos donde los eventos pueden llegar fuera de orden o con latencia. Flink usa watermarks para indicar qu√© tan adelante est√° el sistema en cuanto a la l√≠nea de tiempo de eventos, lo cual le permite agrupar correctamente los datos en ventanas de tiempo y emitir resultados consistentes, incluso cuando algunos datos llegan tarde.</p>
                <p>Adem√°s, Flink puede usar operadores de transformaci√≥n complejos, como uniones de flujos, filtros condicionales, funciones de agregaci√≥n personalizadas, o ventanas deslizantes y acumulativas, todo sin necesidad de almacenar temporalmente el dataset completo.</p>
                <div class="blog-image-grande">
                    <img src="media/flink3.png" alt="">
                </div>
                <h2>Flink vs Spark</h2>
                <p>Apache Spark es un motor poderoso, pero su enfoque hacia el procesamiento de flujos es diferente. Spark Structured Streaming funciona bajo el modelo de micro-batch, donde agrupa los eventos que llegan en un intervalo de tiempo (por ejemplo, cada segundo) y los procesa como un lote peque√±o. Esto permite aprovechar optimizaciones existentes del procesamiento batch, pero a√±ade una latencia inherente entre la llegada de datos y la obtenci√≥n del resultado.</p>
                <p>Flink, en cambio, sigue el paradigma de streaming verdadero (real-time streaming). Cada evento se procesa de inmediato en cuanto llega. No hay necesidad de esperar a agrupar los eventos. Esto se traduce en menor latencia, procesamiento m√°s fino y mayor capacidad de reaccionar a los datos en tiempo real. Adem√°s, Flink soporta una sem√°ntica de procesamiento m√°s precisa sobre event-time, mientras que Spark ha tenido hist√≥ricamente m√°s limitaciones en ese aspecto, aunque ha mejorado con el tiempo.</p>
                <p>Tambi√©n se diferencia en c√≥mo ambos manejan el estado: Flink puede trabajar con estados grandes y complejos distribuidos en todo el cl√∫ster, sin necesidad de persistir resultados externos intermedios. Esto hace que Flink sea m√°s eficiente en casos donde se necesita mantener memoria entre eventos, como en detecci√≥n de patrones o enriquecimiento de datos.</p>
                <p>Sup√≥n que tienes una aplicaci√≥n de detecci√≥n de fraudes que observa millones de transacciones bancarias por segundo. Para detectar comportamientos sospechosos, necesitas:</p>
                <ul style="list-style-type: none;">
                    <li>‚àò Guardar el historial de transacciones de cada usuario (√∫ltimos montos, pa√≠ses, dispositivos).</li>
                    <li>‚àò Detectar si hubo varias transacciones en diferentes pa√≠ses en menos de 5 minutos.</li>
                    <li>‚àò Ver si hay patrones repetitivos (como usar una tarjeta justo antes de que se bloquee).</li>
                </ul>
                <p>Para hacer esto en Flink, cada usuario tiene asociado un estado (por ejemplo, una lista de transacciones recientes, el √∫ltimo pa√≠s donde us√≥ la tarjeta, etc.). Este estado es guardado internamente por Flink y distribuido en memoria (o en disco local si es muy grande) a lo largo de todo el cl√∫ster. Cuando llegan nuevas transacciones, Flink accede al estado del usuario, decide si hay fraude y lo actualiza.</p>
                <p>Ese ‚Äúestado‚Äù puede ser grande y complejo: miles de claves (usuarios), cada una con su propio historial, contadores, mapas, listas, temporizadores, etc. Flink permite manejar todo esto de forma eficiente sin necesidad de consultar una base de datos externa cada vez que llega un evento.</p>
                <div class="blog-image-grande">
                    <img src="media/flink4.png" alt="">
                </div>
                <h2>DAG: Directed Acyclic Graph (Grafo Ac√≠clico Dirigido)</h2>
                <p>En el contexto de la ciencia de datos, un DAG es una representaci√≥n visual y matem√°tica de un flujo de trabajo o un proceso que consta de una serie de tareas (nodos) conectadas por dependencias direccionales (aristas). La caracter√≠stica crucial de un DAG es que no contiene ciclos, lo que significa que no puedes comenzar en un nodo y volver al mismo nodo siguiendo las direcciones de las aristas.</p>
                <p>La importancia de usar DAG's en ciencia de datos se debe a:</p>
                <ul style="list-style-type: none;">
                    <li>◊Ñüïµüèª‚Äç‚ôÄÔ∏è <marcador class="resaltado9">Orquestaci√≥n de flujos de trabajo: </marcador>Los DAGs son fundamentales en herramientas de orquestaci√≥n de flujos de trabajo como Apache Airflow, Prefect, y dbt (data build tool). Permiten definir y gestionar pipelines de datos complejos, especificando el orden en que deben ejecutarse las tareas y las dependencias entre ellas.</li>
                    <li>◊Ñüïµüèª‚Äç‚ôÄÔ∏è <marcador class="resaltado9">Representaci√≥n de pipelines de datos: </marcador>Un DAG puede visualizar claramente el linaje de los datos, mostrando c√≥mo se transforman los datos desde su origen hasta su destino final. Esto facilita la comprensi√≥n, el mantenimiento y la depuraci√≥n de los pipelines.</li>
                    <li>◊Ñüïµüèª‚Äç‚ôÄÔ∏è <marcador class="resaltado9">Paralelizaci√≥n y concurrencia: </marcador>Al definir las dependencias, los sistemas de orquestaci√≥n basados en DAGs pueden ejecutar en paralelo las tareas que no dependen unas de otras, optimizando el tiempo de procesamiento.</li>
                    <li>◊Ñüïµüèª‚Äç‚ôÄÔ∏è <marcador class="resaltado9">Manejo de errores y reintentos: </marcador>Los DAGs permiten definir estrategias espec√≠ficas para el manejo de errores en cada tarea. Si una tarea falla, el sistema puede reintentarla o notificar a los responsables, sin afectar necesariamente a otras partes del flujo de trabajo.</li>
                    <li>◊Ñüïµüèª‚Äç‚ôÄÔ∏è <marcador class="resaltado9">Reproducibilidad: </marcador>Al definir el flujo de trabajo de manera expl√≠cita en un DAG, se facilita la reproducci√≥n de los an√°lisis y los procesos de transformaci√≥n de datos.</li>
                    <li>◊Ñüïµüèª‚Äç‚ôÄÔ∏è <marcador class="resaltado9">Modelado de dependencias: </marcador>En diversas √°reas de la ciencia de datos, como el modelado causal (con redes bayesianas) o la compilaci√≥n de c√≥digo, los DAGs se utilizan para representar las relaciones de dependencia entre variables o componentes.</li>
                </ul>
                <p>En ciencia de datos, un DAG (Grafo Ac√≠clico Dirigido) se utiliza para representar visualmente flujos de trabajo complejos, como en pipelines ETL/ELT donde muestra las dependencias entre las transformaciones de datos, en el entrenamiento de modelos de Machine Learning para definir los pasos desde el preprocesamiento hasta el despliegue, en el an√°lisis de datos para orquestar scripts, y en herramientas como dbt para representar las dependencias entre los diferentes modelos de datos (SQL) en un proyecto de transformaci√≥n.</p>
                <div class="blog-image-grande">
                    <img src="media/flink7.png" alt="">
                </div>
                <h2>Optimizaci√≥n</h2>
                <p>Apache Flink cuenta con un optimizador de consultas muy avanzado, dise√±ado especialmente para el procesamiento de datos en flujo (streaming) y tambi√©n por lotes (batch). Este optimizador analiza el plan l√≥gico que define el usuario (es decir, las transformaciones como filtros, joins, agrupaciones, ventanas, etc.) y lo convierte en un plan f√≠sico m√°s eficiente antes de que se ejecute en el cl√∫ster.</p>
                <p>Su m√©todo de optimizaci√≥n se basa en:</p>
                <ul style="list-style-type: none;">
                    <li>◊ÑüêøÔ∏è <marcador class="resaltado8">Reordenamiento de operadores: </marcador>El optimizador puede cambiar el orden de las operaciones para minimizar el volumen de datos que se mueven por la red. Por ejemplo, si se puede aplicar un filtro antes de un join costoso, lo hace autom√°ticamente.</li>
                    <li>üêøÔ∏è <marcador class="resaltado8">Uso de estad√≠sticas: </marcador>Cuando est√°n disponibles, Flink utiliza estad√≠sticas de los datos (como el n√∫mero de filas, distribuci√≥n de claves, tama√±os) para tomar decisiones sobre el mejor plan de ejecuci√≥n.</li>
                    <li>üêøÔ∏è <marcador class="resaltado8">Optimizaci√≥n de joins: </marcador>Uno de los puntos m√°s complejos en sistemas distribuidos. Flink decide si conviene hacer un broadcast join (enviar una tabla peque√±a a todos los nodos), un hash join, o incluso un stateful join en streaming con ventanas temporales. Esta decisi√≥n es cr√≠tica para el rendimiento.</li>
                    <li>üêøÔ∏è <marcador class="resaltado8">Pipelines de ejecuci√≥n eficientes: </marcador>Flink convierte las operaciones en tareas altamente optimizadas, muchas de las cuales pueden operar sincr√≥nicamente dentro del mismo proceso si detecta que no hace falta pasar datos entre nodos.</li>
                </ul>
                <p>Este proceso de optimizaci√≥n es autom√°tico y permite a Flink ejecutar trabajos de forma muy eficiente, especialmente en flujos donde cada milisegundo importa.</p>
                <div class="blog-image-grande">
                    <img src="media/flink5.png" alt="">
                </div>
                <h2>Tolerancia a fallos</h2>
                <p>La tolerancia a fallos en Apache Flink se basa en un mecanismo robusto y eficiente de <marcador class="resaltado8">checkpoints autom√°ticos</marcador class="resaltado8"> y <marcador class="resaltado8">savepoints manuales</marcador class="resaltado8">. Estos puntos de control permiten recuperar el estado completo del sistema ante cualquier fallo (ya sea una ca√≠da de nodo, error de red o reinicio inesperado) sin perder datos ni procesar eventos duplicados.</p>
                <p>Piensa en los checkpoints como fotos sincronizadas de todos los componentes que procesan los datos. Si ocurre un error, Flink puede volver a esa foto y continuar desde ah√≠. Los savepoints, por su parte, son capturas manuales que t√∫ decides cu√°ndo tomar, √∫tiles por ejemplo para actualizaciones de c√≥digo.</p>
                <p>El mecanismo subyacente funciona as√≠:</p>
                <ul style="list-style-type: none;">
                    <li>üêøÔ∏è <marcador class="resaltado8">Checkpoint Coordinator:</marcador class="resaltado8"> Es el nodo maestro que inicia el proceso de checkpoint. Env√≠a una se√±al a todas las tareas del job (source, operadores y sink) para que tomen una instant√°nea sincronizada del estado.</li>
                    <li>üêøÔ∏è <marcador class="resaltado8">Source:</marcador class="resaltado8"> Guarda los <em>offsets</em> de los datos de entrada. Es decir, el punto exacto hasta donde ha le√≠do del sistema fuente (por ejemplo, Kafka o archivos).</li>
                    <li>üêøÔ∏è <marcador class="resaltado8">Operadores intermedios:</marcador class="resaltado8"> Guardan su estado interno, como buffers, listas, contadores o ventanas. Este estado se almacena en un <marcador class="resaltado8">state backend</marcador class="resaltado8">, que puede ser en memoria o usando RocksDB para escalar.</li>
                    <li>üêøÔ∏è <marcador class="resaltado8">Sink:</marcador class="resaltado8"> Si es transaccional, primero realiza un <em>pre-commit</em> de los datos que ya ha recibido. Esto significa que los datos se escriben de forma segura, pero no se hacen visibles hasta que el checkpoint es exitoso.</li>
                    <li>üêøÔ∏è <marcador class="resaltado8">Consistencia exactly-once:</marcador class="resaltado8"> El checkpoint no se considera v√°lido hasta que todas las tareas confirman al coordinador que su parte del estado ha sido correctamente persistida. Solo entonces se hace un commit final en el sink. Esto evita duplicados y garantiza procesamiento exactamente una vez.</li>
                    <li>üêøÔ∏è <marcador class="resaltado8">Almacenamiento persistente:</marcador class="resaltado8"> El estado y los offsets se guardan en sistemas como S3, HDFS o sistemas distribuidos (DFS), permitiendo una recuperaci√≥n segura incluso tras reinicios completos del cl√∫ster.</li>                
                    <li>üêøÔ∏è <marcador class="resaltado8">Savepoints manuales:</marcador class="resaltado8"> A diferencia de los checkpoints, son controlados por el usuario. Se utilizan para pausas planificadas, migraciones de versi√≥n, o reinicios desde un punto espec√≠fico. Los savepoints tambi√©n se almacenan en un DFS y pueden ser retomados expl√≠citamente.</li>
                </ul>                
                <p>Este dise√±o hace que Flink sea ideal para sistemas donde la fiabilidad es cr√≠tica, como procesamiento de pagos, detecci√≥n de fraudes o sistemas financieros en tiempo real.</p>
                <div class="blog-image-grande">
                    <img src="media/flink6.png" alt="">
                </div>
                <p>Supongamos que tienes una aplicaci√≥n de procesamiento de pagos en tiempo real. Flink guarda el estado de cada usuario: cu√°ntas transacciones hizo, de qu√© tipo, desde qu√© pa√≠s, etc. Si un nodo que procesa a cierto grupo de usuarios se cae, Flink autom√°ticamente reprograma esa parte del trabajo en otro nodo y restaura todo el estado desde el √∫ltimo checkpoint. El procesamiento contin√∫a casi sin interrupciones, y ninguna transacci√≥n se procesa dos veces ni se pierde.</p>
                <h2>Instalaci√≥n de Apache Flink en modo Standalone</h2>
                <p>Apache Flink puede ejecutarse como un cl√∫ster en modo "standalone", lo que significa que no depende de herramientas como YARN o Kubernetes para su orquestaci√≥n. Este enfoque es √∫til cuando deseas tener control total sobre las m√°quinas y la configuraci√≥n del entorno.</p>
                <p>En este ejemplo, se usa una configuraci√≥n de tres nodos, cada uno ejecutando uno o m√°s componentes de Flink (JobManager o TaskManager).</p>
                <p>Primero, aseg√∫rate de tener Java instalado y configurado correctamente en todos los nodos. Luego descarga y descomprime Flink en una ruta compartida o r√©plica local en cada nodo.</p>
                <p>Sitio oficial de descarga: <a href="https://nightlies.apache.org/flink/flink-docs-release-1.19/docs/try-flink/local_installation/" target="blank">Apache Flink</a>.</p>
                <div class="contenedor">
                    <div class="etiqueta">
                        Creaci√≥n de los contenedores con Docker: 
                    </div>
                    <div class="comandos">
                        <input type="text" class="text" value="sudo podman run -it --rm ubuntu:latest" oninput="ajustarAncho(this)">
                        <button><i class="fa fa-clone"></i><span> Copy</span></button>
                    </div>
                </div>
                <p>Es necesario crear 3 contenedores en diferentes terminales, para cada uno de los nodos del cluster.</p>
                <div class="contenedor">
                    <div class="etiqueta">
                        Verificar las direcciones IP: 
                    </div>
                    <div class="comandos">
                        <input type="text" class="text" value="cat /etc/hosts" oninput="ajustarAncho(this)">
                        <button><i class="fa fa-clone"></i><span> Copy</span></button>
                    </div>
                </div>
                <div class="contenedor">
                    <div class="etiqueta">Verificar el nombre del host:</div>
                    <div class="comandos">
                        <input type="text" class="text" value="hostname" oninput="ajustarancho(this)">
                        <button><i class="fa fa-clone"></i><span> copy</span></button>
                    </div>
                </div>
                <div class="contenedor">
                    <div class="etiqueta">
                        Instalar las dependencias en los contenedores: 
                    </div>
                    <div class="comandos">
                        <input type="text" class="text" value="apt update && apt install -y nano wget curl openjdk-11-jdk" oninput="ajustarAncho(this)">
                        <button><i class="fa fa-clone"></i><span> Copy</span></button>
                    </div>
                </div>
                <div class="contenedor">
                    <div class="etiqueta">Descarga Apache Flink:</div>
                    <div class="comandos">
                        <input type="text" class="text" value="wget https://dlcdn.apache.org/flink/flink-2.0.0/flink-2.0.0-bin-scala_2.12.tgz --no-check-certificate" oninput="ajustarancho(this)">
                        <button><i class="fa fa-clone"></i><span> copy</span></button>
                    </div>
                </div>
                <div class="contenedor">
                    <div class="etiqueta">Extrae el paquete descargado:</div>
                    <div class="comandos">
                        <input type="text" class="text" value="sudo tar -zxvf flink-2.0.0-bin-scala_2.12.tgz -C /opt" oninput="ajustarancho(this)">
                        <button><i class="fa fa-clone"></i><span> copy</span></button>
                    </div>
                </div>
                <div class="contenedor">
                    <div class="etiqueta">Crea un enlace simb√≥lico:</div>
                    <div class="comandos">
                        <input type="text" class="text" value="sudo ln -sfn /opt/flink-2.0.0 flink" oninput="ajustarancho(this)">
                        <button><i class="fa fa-clone"></i><span> copy</span></button>
                    </div>
                </div>
                <div class="contenedor">
                    <div class="etiqueta">Cambia el propietario del directorio (opcional):</div>
                    <div class="comandos">
                        <input type="text" class="text" value="sudo chown -R usuario:usuario /opt/flink-2.0.0" oninput="ajustarancho(this)">
                        <button><i class="fa fa-clone"></i><span> copy</span></button>
                    </div>
                </div>
                <h6>Configuraci√≥n del nodo maestro</h6>
                <p>‚å≠ Modifica el archivo de configuraci√≥n con los siguientes valores utilizando el siguiente comando: <marcador class="subrayado">nano /opt/flink-2.0.0/conf/config.yaml</marcador>.</p>
                <ul>
                    <li>Los campos bind-host deben tener el valor 0.0.0.0 como direcci√≥n.</li>
                    <li>los campos address deben contener el nombre del host correspondiente.</li>
                </ul>
                <p>‚ùè Configurar el master en el nodo 1.</p>
                <div id="terminal">
                    <section id="terminal__bar">
                        <div id="bar__buttons">
                        <button class="bar__button" id="bar__button--exit">&#10005;</button>
                        <button class="bar__button">&#9633;</button>
                        <button class="bar__button">&#9472;</button>
                        </div>
                        <p id="bar__user">ryuzak1@ubuntu: ~</p>
                    </section>
                    <section id="terminal__body">
                        <div id="terminal__prompt">
                        <span id="terminal__prompt--command"><marcador class="user">ryuzak1@ubuntu:</marcador><marcador class="location">~</marcador><marcador class="bling">$&nbsp;</marcador><marcador class="sudo"></marcador><marcador class="tool">nano</marcador> /opt/flink-2.0.0/conf/config.yaml <marcador class="param"></marcador></span>    
                        </div>
                        <div class="command-response-container">
                            <span id="terminal__prompt--response" class="multiline-text">
# To enable this, set the bind-host address to one that has access to an outside facing network
# interface, such as 0.0.0.0.
bind-host: 0.0.0.0
rpc:
    # The external address of the host on which the JobManager runs and can be
    # reached by the TaskManagers and any clients which want to connect. This setting
    # is only used in Standalone mode and may be overwritten on the JobManager side
    # by specifying the --host  parameter of the bin/jobmanager.sh executable.
    # In high availability mode, if you use the bin/start-cluster.sh script and setup
    # the conf/masters file, this will be taken care of automatically. Yarn
    # automatically configure the host name based on the hostname of the node where the
    # JobManager runs.
    address: NombreDeHost
    # The RPC port where the JobManager is reachable.
    port: 6123
memory:
    process:
    # The total process memory size for the JobManager.
    # Note this accounts for all memory usage within the JobManager process, including JVM metaspace and other overhead.
    size: 1600m
execution:
    # The failover strategy, i.e., how the job computation recovers from task failures.
    # Only restart tasks that may have been affected by the task failure, which typically includes
    # downstream tasks and potentially upstream tasks if their produced data is no longer available for consumption.
    failover-strategy: region 
                            </span>
                        </div>
                    </section>
                </div>
                <p>‚ùè Verificar los cambios:</p>
                <div id="terminal">
                    <section id="terminal__bar">
                        <div id="bar__buttons">
                        <button class="bar__button" id="bar__button--exit">&#10005;</button>
                        <button class="bar__button">&#9633;</button>
                        <button class="bar__button">&#9472;</button>
                        </div>
                        <p id="bar__user">ryuzak1@ubuntu: ~</p>
                    </section>
                    <section id="terminal__body">
                        <div id="terminal__prompt">
                        <span id="terminal__prompt--command"><marcador class="user">ryuzak1@ubuntu:</marcador><marcador class="location">~</marcador><marcador class="bling">$&nbsp;</marcador><marcador class="sudo"></marcador><marcador class="tool">cat</marcador> config.yaml | <marcador class="tool">grep</marcador> <marcador class="param">-vE</marcador> '^\s*#|^\s*$' | <marcador class="tool">grep</marcador> <marcador class="param">-vE</marcador> 'env|java|opts|all'</span>    
                        </div>
                        <div class="command-response-container">
                            <span id="terminal__prompt--response" class="multiline-text">jobmanager:
bind-host: 0.0.0.0
rpc:
    address: NombreDeHost
    port: 6123
memory:
    process:
    size: 1600m
execution:
    failover-strategy: region
taskmanager:
bind-host: 0.0.0.0
host: NombreDeHost
numberOfTaskSlots: 2    
                            </span>
                        </div>
                    </section>
                </div>
                <p>‚å≠ En el archivo <marcador class="subrayado">/opt/flink-2.0.0/conf/masters</marcador>, en el nodo donde se iniciar√° el JobManager, escribe el nombre del host seguido del puerto (por defecto 6123). Este nodo actuar√° como el JobManager del cl√∫ster.</p>
                <div class="contenedor">
                    <div class="etiqueta">Configura el JobManager:</div>
                    <div class="comandos">
                        <input type="text" class="text" value="nano /opt/flink-2.0.0/conf/masters" oninput="ajustarancho(this)">
                        <button><i class="fa fa-clone"></i><span> copy</span></button>
                    </div>
                </div>
                <div class="archivo">
NombreDeHost1:8081
                </div>
                <p>‚å≠ En todos los nodos, configura los TaskManagers editando el archivo <marcador class="subrayado">/opt/flink-2.0.0/conf/workers</marcador>.</p>
                <div class="contenedor">
                    <div class="etiqueta">Para ello, utiliza el siguiente comando: </div>
                    <div class="comandos">
                        <input type="text" class="text" value="nano /opt/flink-2.0.0/conf/workers" oninput="ajustarancho(this)">
                        <button><i class="fa fa-clone"></i><span> copy</span></button>
                    </div>
                </div>
                <div class="archivo">
NombreDeHost1
NombreDeHost2
NombreDeHost3
                </div>
                <p>En esta configuraci√≥n se asignan los siguientes roles:</p>
                <ul style="list-style-type: none;">
                    <li>‚àò <marcador class="resaltado8">192.168.88.151</marcador>: JobManager y TaskManager</li>
                    <li>‚àò <marcador class="resaltado8">192.168.88.152</marcador>: TaskManager</li>
                    <li>‚àò <marcador class="resaltado8">192.168.88.153</marcador>: TaskManager</li>
                </ul>
                <h6>Configuraci√≥n de los nodos workers</h6>
                <h6>Iniciar el cl√∫ster</h6>
                <div class="contenedor">
                    <div class="etiqueta">Inicia el cl√∫ster de Flink:</div>
                    <div class="comandos">
                        <input type="text" class="text" value="./bin/start-cluster.sh" oninput="ajustarancho(this)">
                        <button><i class="fa fa-clone"></i><span> copy</span></button>
                    </div>
                </div>
                <h6>Verificaci√≥n y prueba</h6>
                <p>Una vez iniciado, puedes verificar que el cl√∫ster est√© funcionando accediendo a la interfaz web desde tu navegador:</p>
                <div class="contenedor">
                    <div class="etiqueta">Interfaz web:</div>
                    <div class="comandos">
                        <input type="text" class="text" value="http://192.168.88.151:8081" oninput="ajustarancho(this)">
                        <button><i class="fa fa-clone"></i><span> copy</span></button>
                    </div>
                </div>
                <p>En esa interfaz deber√≠as poder ver los TaskManagers conectados, el estado del JobManager y otros detalles de monitoreo.</p>
                <p>Tambi√©n puedes revisar los logs en el directorio <marcador class="resaltado1">log/</marcador> para diagnosticar cualquier problema o asegurarte de que todos los nodos se hayan conectado correctamente.</p>
                <br>
                <br>
            </div>
        </div>       
    </main>
    <script src="../js/script.js"></script>
</body>
</html>